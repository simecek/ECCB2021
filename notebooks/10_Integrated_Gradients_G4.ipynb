{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Integrated_Gradients.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOIxrOLvfT0ExmpTwoZJiSn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simecek/ECCB2021/blob/main/notebooks/10_Integrated_Gradients_G4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SBhmsvbdrS9"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFO7oytsYB_L"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, BatchNormalization, MaxPooling1D, Dropout, GlobalAveragePooling1D, Dense\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, HTML"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSUVeyHtYb6C"
      },
      "source": [
        "# get train dataset\n",
        "!wget --quiet https://raw.githubusercontent.com/ML-Bioinfo-CEITEC/penguinn/master/Datasets/train_set_1_1.txt\n",
        "\n",
        "nucleo_dic = {\n",
        "    \"A\": 0,\n",
        "    \"C\": 1,\n",
        "    \"T\": 2,\n",
        "    \"G\": 3,\n",
        "    \"N\": 4,\n",
        "}\n",
        "\n",
        "df_train = pd.read_csv(\"train_set_1_1.txt\", sep='\\t', names=['sequence', 'label'])\n",
        "\n",
        "# translate text labels to numbers 0, 1\n",
        "labels_train = np.array(list(map((lambda x: 1 if x == 'positive' else 0), list(df_train['label']))))\n",
        "dataset_train = df_train['sequence'].tolist()\n",
        "# numericalize using the dictionary\n",
        "dataset_ordinal_train = [[nucleo_dic[letter] for letter in sequence] for sequence in dataset_train]\n",
        "# translate number values to one-hot vectors\n",
        "dataset_onehot_train = tf.one_hot(dataset_ordinal_train, depth=5)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6NicFJVY2h2"
      },
      "source": [
        "# get test dataset\n",
        "!wget --quiet https://raw.githubusercontent.com/ML-Bioinfo-CEITEC/penguinn/master/Datasets/test_set_1_1.txt\n",
        "\n",
        "# preprocess the test set similarly\n",
        "df_test = pd.read_csv(\"test_set_1_1.txt\", sep='\\t', names=['sequence', 'label'])\n",
        "\n",
        "labels_test = np.array(list(map((lambda x: 1 if x == 'positive' else 0), list(df_test['label']))))\n",
        "dataset_test = df_test['sequence'].tolist()\n",
        "\n",
        "# we use the same nucleo_dic as on the example before\n",
        "dataset_ordinal_test = [[nucleo_dic[letter] for letter in sequence] for sequence in dataset_test]\n",
        "dataset_onehot_test = tf.one_hot(dataset_ordinal_test, depth=5)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsCkvaT_dxDa"
      },
      "source": [
        "## Model\n",
        "\n",
        "We have adapted model from our original [paper](https://www.frontiersin.org/articles/10.3389/fgene.2020.568546/full). Note it is sligtly more complex model than what we have seen yesterday."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hQFWf3uZWG6"
      },
      "source": [
        "model = Sequential([\n",
        "        Conv1D(32, kernel_size=8, data_format='channels_last', activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(),\n",
        "        Conv1D(16, kernel_size=8, data_format='channels_last', activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(),\n",
        "        Conv1D(4, kernel_size=8, data_format='channels_last', activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(),\n",
        "        Dropout(0.3),\n",
        "        GlobalAveragePooling1D(),\n",
        "        Dense(1)])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YROigDsQZ8Pd"
      },
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(0.005),\n",
        "    loss=tf.keras.losses.binary_crossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-JO2cahgodo"
      },
      "source": [
        "## Training and saving the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2o83ueDZv59",
        "outputId": "09fd4969-b5b2-4339-a911-144b5a8e1c76"
      },
      "source": [
        "model.fit(\n",
        "    dataset_onehot_train,\n",
        "    labels_train,\n",
        "    batch_size=128,\n",
        "    epochs=5,\n",
        "    validation_split=0.3\n",
        ")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1641/1641 [==============================] - 25s 14ms/step - loss: 0.2151 - accuracy: 0.9378 - val_loss: 0.1725 - val_accuracy: 0.9467\n",
            "Epoch 2/5\n",
            "1641/1641 [==============================] - 21s 13ms/step - loss: 0.1697 - accuracy: 0.9492 - val_loss: 0.2124 - val_accuracy: 0.9503\n",
            "Epoch 3/5\n",
            "1641/1641 [==============================] - 21s 13ms/step - loss: 0.1796 - accuracy: 0.9454 - val_loss: 0.1448 - val_accuracy: 0.9557\n",
            "Epoch 4/5\n",
            "1641/1641 [==============================] - 21s 13ms/step - loss: 0.2583 - accuracy: 0.9311 - val_loss: 0.2083 - val_accuracy: 0.9465\n",
            "Epoch 5/5\n",
            "1641/1641 [==============================] - 21s 13ms/step - loss: 0.1904 - accuracy: 0.9405 - val_loss: 0.1407 - val_accuracy: 0.9536\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f235018dcd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bncLlx3PZ7GJ"
      },
      "source": [
        "model.save(\"cnn_3epochs.h5\", save_format='h5')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJdOi11WhIhC"
      },
      "source": [
        "model = tf.keras.models.load_model('cnn_3epochs.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbKn2pf5mgcw"
      },
      "source": [
        "## Integrated Gradients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbphLAYIminT"
      },
      "source": [
        "def generate_alphas(m_steps=50, method='riemann_trapezoidal'):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "    m_steps(Tensor): A 0D tensor of an int corresponding to the number of linear\n",
        "    interpolation steps for computing an approximate integral. Default is 50.\n",
        "    method(str): A string representing the integral approximation method. The\n",
        "       following methods are implemented:\n",
        "      - riemann_trapezoidal(default)\n",
        "      - riemann_left\n",
        "      - riemann_midpoint\n",
        "      - riemann_right\n",
        "    Returns:\n",
        "      alphas(Tensor): A 1D tensor of uniformly spaced floats with the shape\n",
        "      (m_steps,).\n",
        "      \"\"\"\n",
        "    m_steps_float = tf.cast(m_steps, float)\n",
        "\n",
        "    if method == 'riemann_trapezoidal':\n",
        "        alphas = tf.linspace(0.0, 1.0, m_steps+1)\n",
        "    elif method == 'riemann_left':\n",
        "        alphas = tf.linspace(0.0, 1.0 - (1.0 / m_steps_float), m_steps)\n",
        "    elif method == 'riemann_midpoint':\n",
        "        alphas = tf.linspace(1.0 / (2.0 * m_steps_float), 1.0 - 1.0 / (2.0 * m_steps_float), m_steps)\n",
        "    elif method == 'riemann_right':\n",
        "        alphas = tf.linspace(1.0 / m_steps_float, 1.0, m_steps)\n",
        "    else:\n",
        "        raise AssertionError(\"Provided Riemann approximation method is not valid.\")\n",
        "\n",
        "    return alphas\n",
        "\n",
        "def generate_path_inputs(baseline, input, alphas):\n",
        "    \"\"\"\n",
        "    Generate interpolated 'images' along a linear path at alpha intervals between a baseline tensor\n",
        "\n",
        "    baseline: 2D, shape: (200, 4)\n",
        "    input: preprocessed sample, shape: (200, 4)\n",
        "    alphas: list of steps in interpolated image ,shape: (21)\n",
        "\n",
        "\n",
        "    return: shape (21, 200, 4)\n",
        "    \"\"\"\n",
        "    # Expand dimensions for vectorized computation of interpolations.\n",
        "    alphas_x = alphas[:, tf.newaxis, tf.newaxis]\n",
        "    baseline_x = tf.expand_dims(baseline, axis=0)\n",
        "    input_x = tf.expand_dims(input, axis=0)\n",
        "    delta = input_x - baseline_x\n",
        "    path_inputs = baseline_x + alphas_x * delta\n",
        "\n",
        "    return path_inputs\n",
        "\n",
        "def compute_gradients(model, path_inputs):\n",
        "    \"\"\"\n",
        "    compute dependency of each field on whole result, compared to interpolated 'images'\n",
        "\n",
        "    :param model: trained model\n",
        "    :param path_inputs: interpolated tensors, shape: (21, 200, 4)\n",
        "    :return: shape: (21, 200, 4)\n",
        "    \"\"\"\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(path_inputs)\n",
        "        predictions = model(path_inputs)\n",
        "\n",
        "        outputs = []\n",
        "        for envelope in predictions:\n",
        "            outputs.append(envelope[0])\n",
        "        outputs = tf.convert_to_tensor(outputs, dtype=tf.float32)\n",
        "\n",
        "    gradients = tape.gradient(outputs, path_inputs)\n",
        "    return gradients\n",
        "\n",
        "def integral_approximation(gradients, method='riemann_trapezoidal'):\n",
        "    \"\"\"Compute numerical approximation of integral from gradients.\n",
        "    Args:\n",
        "    gradients(Tensor): A 4D tensor of floats with the shape\n",
        "    (m_steps, img_height, img_width, 3).\n",
        "    method(str): A string representing the integral approximation method. The\n",
        "    following methods are implemented:\n",
        "    - riemann_trapezoidal(default)\n",
        "    - riemann_left\n",
        "    - riemann_midpoint\n",
        "    - riemann_right\n",
        "    Returns:\n",
        "    integrated_gradients(Tensor): A 3D tensor of floats with the shape\n",
        "    (img_height, img_width, 3).\n",
        "    \"\"\"\n",
        "    if method == 'riemann_trapezoidal':\n",
        "        grads = (gradients[:-1] + gradients[1:]) / tf.constant(2.0)\n",
        "    elif method == 'riemann_left':\n",
        "        grads = gradients\n",
        "    elif method == 'riemann_midpoint':\n",
        "        grads = gradients\n",
        "    elif method == 'riemann_right':\n",
        "        grads = gradients\n",
        "    else:\n",
        "        raise AssertionError(\"Provided Riemann approximation method is not valid.\")\n",
        "\n",
        "    # Average integration approximation.\n",
        "    integrated_gradients = tf.math.reduce_mean(grads, axis=0)\n",
        "\n",
        "    return integrated_gradients\n",
        "\n",
        "def integrated_gradients(model, baseline, input, m_steps=50, method='riemann_trapezoidal',\n",
        "                         batch_size=32):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      model(keras.Model): A trained model to generate predictions and inspect.\n",
        "      baseline(Tensor): 2D, shape: (200, 4)\n",
        "      input(Tensor): preprocessed sample, shape: (200, 4)\n",
        "      m_steps(Tensor): A 0D tensor of an integer corresponding to the number of\n",
        "        linear interpolation steps for computing an approximate integral.\n",
        "      method(str): A string representing the integral approximation method. The\n",
        "        following methods are implemented:\n",
        "        - riemann_trapezoidal(default)\n",
        "        - riemann_left\n",
        "        - riemann_midpoint\n",
        "        - riemann_right\n",
        "      batch_size(Tensor): A 0D tensor of an integer corresponding to a batch\n",
        "        size for alpha to scale computation and prevent OOM errors. Note: needs to\n",
        "        be tf.int64 and shoud be < m_steps. Default value is 32.\n",
        "    Returns:\n",
        "      integrated_gradients(Tensor): A 2D tensor of floats with the same\n",
        "        shape as the input tensor.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Generate alphas.\n",
        "    alphas = generate_alphas(m_steps=m_steps,\n",
        "                             method=method)\n",
        "\n",
        "    # Initialize TensorArray outside loop to collect gradients. Note: this data structure\n",
        "    gradient_batches = tf.TensorArray(tf.float32, size=m_steps + 1)\n",
        "\n",
        "    # Iterate alphas range and batch computation for speed, memory efficiency, and scaling to larger m_steps.\n",
        "    for alpha in tf.range(0, len(alphas), batch_size):\n",
        "        from_ = alpha\n",
        "        to = tf.minimum(from_ + batch_size, len(alphas))\n",
        "        alpha_batch = alphas[from_:to]\n",
        "\n",
        "        # 2. Generate interpolated inputs between baseline and input.\n",
        "        interpolated_path_input_batch = generate_path_inputs(baseline=baseline,\n",
        "                                                             input=input,\n",
        "                                                             alphas=alpha_batch)\n",
        "\n",
        "        # 3. Compute gradients between model outputs and interpolated inputs.\n",
        "        gradient_batch = compute_gradients(model=model,\n",
        "                                           path_inputs=interpolated_path_input_batch)\n",
        "\n",
        "        # Write batch indices and gradients to TensorArray.\n",
        "        gradient_batches = gradient_batches.scatter(tf.range(from_, to), gradient_batch)\n",
        "\n",
        "    # Stack path gradients together row-wise into single tensor.\n",
        "    total_gradients = gradient_batches.stack()\n",
        "\n",
        "    # 4. Integral approximation through averaging gradients.\n",
        "    avg_gradients = integral_approximation(gradients=total_gradients,\n",
        "                                           method=method)\n",
        "\n",
        "    # 5. Scale integrated gradients with respect to input.\n",
        "    integrated_gradients = (input - baseline) * avg_gradients\n",
        "\n",
        "    return integrated_gradients\n",
        "\n",
        "def choose_validation_points(integrated_gradients):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "          integrated_gradients(Tensor): A 2D tensor of floats with shape (200, 4).\n",
        "    Return: List of attributes for highlighting DNA string sequence\n",
        "    \"\"\"\n",
        "    attr = np.zeros(200)\n",
        "    for i in range(200):\n",
        "        for j in range(4):\n",
        "            if integrated_gradients[i][j].numpy() == 0:\n",
        "                continue\n",
        "            attr[i] = integrated_gradients[i][j].numpy()\n",
        "    return attr\n",
        "\n",
        "def visualize_token_attrs(sequence, attrs):\n",
        "    \"\"\"\n",
        "    Visualize attributions for given set of tokens.\n",
        "    Args:\n",
        "    - tokens: An array of tokens\n",
        "    - attrs: An array of attributions, of same size as 'tokens',\n",
        "      with attrs[i] being the attribution to tokens[i]\n",
        "\n",
        "    Returns:\n",
        "    - visualization: HTML text with colorful representation of DNA sequence\n",
        "        build on model prediction\n",
        "    \"\"\"\n",
        "\n",
        "    def get_color(attr):\n",
        "        if attr > 0:\n",
        "            red = int(128 * attr) + 127\n",
        "            green = 128 - int(64 * attr)\n",
        "            blue = 128 - int(64 * attr)\n",
        "        else:\n",
        "            red = 128 + int(64 * attr)\n",
        "            green = 128 + int(64 * attr)\n",
        "            blue = int(-128 * attr) + 127\n",
        "\n",
        "        return red, green, blue\n",
        "\n",
        "    # normalize attributions for visualization.\n",
        "    bound = max(abs(max(attrs)), abs(min(attrs)))\n",
        "    attrs = attrs / bound\n",
        "    html_text = \"\"\n",
        "    for i, tok in enumerate(sequence):\n",
        "        r, g, b = get_color(attrs[i])\n",
        "        if abs(attrs[i]) > 0.5:\n",
        "          html_text += \" <span style='color:rgb(%d,%d,%d);font-weight:bold'>%s</span>\" % (r, g, b, tok)\n",
        "        else: \n",
        "          html_text += \" <span style='color:rgb(%d,%d,%d)'>%s</span>\" % (r, g, b, tok)\n",
        "\n",
        "    return html_text"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlkegTxYn36E",
        "outputId": "87390346-6393-4153-9ac4-9d312854567b"
      },
      "source": [
        "seq = 'AAAGAAGAGACCAAGACGGAAGACCCAATCGGACCGGGAGGTCCGGGGAGACGTGTCGGGGATCGGGACTTGACTGTGCTTACCAAAGGACCTAACGGAGGGGTCCATAGGAGTCTTGCGGGACTCCCTGGCACTGGAGTAGTATCGACATAAGGGTCACGGACGTTCCATTTAGTGAGCCATTTATAAACCACTATCAA'\n",
        "\n",
        "channel={\n",
        "            'A': 0,\n",
        "            'T': 1,\n",
        "            'C': 2,\n",
        "            'G': 3,\n",
        "            'N': 4\n",
        "        }\n",
        "seq_onehot = tf.one_hot([channel[c] for c in seq], depth=5)\n",
        "\n",
        "#seq_onehot = tf.convert_to_tensor(seq_onehot, dtype=tf.float32)[:,:4]\n",
        "seq_onehot.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([200, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "DcEBQDxlokr0",
        "outputId": "4d44227f-1893-4b80-da4e-18c04912d045"
      },
      "source": [
        "baseline = tf.zeros(shape=(200, 5))\n",
        "\n",
        "ig_attribution = integrated_gradients(model, baseline, seq_onehot)\n",
        "attrs = choose_validation_points(ig_attribution)\n",
        "\n",
        "visualisation = visualize_token_attrs(seq, attrs)\n",
        "HTML(visualisation)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              " <span style='color:rgb(127,128,128)'>A</span> <span style='color:rgb(128,128,127)'>A</span> <span style='color:rgb(128,128,127)'>A</span> <span style='color:rgb(127,128,128)'>G</span> <span style='color:rgb(128,128,127)'>A</span> <span style='color:rgb(127,128,128)'>A</span> <span style='color:rgb(128,128,127)'>G</span> <span style='color:rgb(128,128,127)'>A</span> <span style='color:rgb(128,128,127)'>G</span> <span style='color:rgb(127,127,129)'>A</span> <span style='color:rgb(127,128,128)'>C</span> <span style='color:rgb(128,128,127)'>C</span> <span style='color:rgb(128,128,128)'>A</span> <span style='color:rgb(127,127,130)'>A</span> <span style='color:rgb(128,128,128)'>G</span> <span style='color:rgb(127,127,129)'>A</span> <span style='color:rgb(128,128,128)'>C</span> <span style='color:rgb(128,128,127)'>G</span> <span style='color:rgb(126,126,131)'>G</span> <span style='color:rgb(128,128,128)'>A</span> <span style='color:rgb(132,126,126)'>A</span> <span style='color:rgb(122,122,140)'>G</span> <span style='color:rgb(125,125,134)'>A</span> <span style='color:rgb(127,128,128)'>C</span> <span style='color:rgb(128,128,127)'>C</span> <span style='color:rgb(127,128,128)'>C</span> <span style='color:rgb(128,128,127)'>A</span> <span style='color:rgb(129,127,127)'>A</span> <span style='color:rgb(119,119,145)'>T</span> <span style='color:rgb(124,124,135)'>C</span> <span style='color:rgb(146,119,119)'>G</span> <span style='color:rgb(126,126,132)'>G</span> <span style='color:rgb(117,117,150)'>A</span> <span style='color:rgb(124,124,136)'>C</span> <span style='color:rgb(119,119,145)'>C</span> <span style='color:rgb(195,94,94);font-weight:bold'>G</span> <span style='color:rgb(217,83,83);font-weight:bold'>G</span> <span style='color:rgb(190,97,97)'>G</span> <span style='color:rgb(106,106,171)'>A</span> <span style='color:rgb(182,101,101)'>G</span> <span style='color:rgb(164,110,110)'>G</span> <span style='color:rgb(76,76,232);font-weight:bold'>T</span> <span style='color:rgb(112,112,160)'>C</span> <span style='color:rgb(117,117,150)'>C</span> <span style='color:rgb(210,87,87);font-weight:bold'>G</span> <span style='color:rgb(255,64,64);font-weight:bold'>G</span> <span style='color:rgb(246,69,69);font-weight:bold'>G</span> <span style='color:rgb(202,91,91);font-weight:bold'>G</span> <span style='color:rgb(107,107,169)'>A</span> <span style='color:rgb(159,112,112)'>G</span> <span style='color:rgb(106,106,171)'>A</span> <span style='color:rgb(113,113,158)'>C</span> <span style='color:rgb(134,125,125)'>G</span> <span style='color:rgb(98,98,187)'>T</span> <span style='color:rgb(167,108,108)'>G</span> <span style='color:rgb(94,94,196);font-weight:bold'>T</span> <span style='color:rgb(107,107,170)'>C</span> <span style='color:rgb(171,106,106)'>G</span> <span style='color:rgb(228,78,78);font-weight:bold'>G</span> <span style='color:rgb(248,68,68);font-weight:bold'>G</span> <span style='color:rgb(214,85,85);font-weight:bold'>G</span> <span style='color:rgb(112,112,160)'>A</span> <span style='color:rgb(114,114,155)'>T</span> <span style='color:rgb(124,124,136)'>C</span> <span style='color:rgb(186,99,99)'>G</span> <span style='color:rgb(177,103,103)'>G</span> <span style='color:rgb(166,109,109)'>G</span> <span style='color:rgb(119,119,146)'>A</span> <span style='color:rgb(125,125,133)'>C</span> <span style='color:rgb(125,125,134)'>T</span> <span style='color:rgb(134,125,125)'>T</span> <span style='color:rgb(150,117,117)'>G</span> <span style='color:rgb(128,128,128)'>A</span> <span style='color:rgb(124,124,135)'>C</span> <span style='color:rgb(126,126,132)'>T</span> <span style='color:rgb(132,126,126)'>G</span> <span style='color:rgb(128,128,128)'>T</span> <span style='color:rgb(133,125,125)'>G</span> <span style='color:rgb(124,124,136)'>C</span> <span style='color:rgb(127,127,130)'>T</span> <span style='color:rgb(125,125,134)'>T</span> <span style='color:rgb(123,123,138)'>A</span> <span style='color:rgb(124,124,135)'>C</span> <span style='color:rgb(119,119,145)'>C</span> <span style='color:rgb(128,128,128)'>A</span> <span style='color:rgb(129,127,127)'>A</span> <span style='color:rgb(122,122,139)'>A</span> <span style='color:rgb(133,125,125)'>G</span> <span style='color:rgb(124,124,135)'>G</span> <span style='color:rgb(123,123,137)'>A</span> <span style='color:rgb(124,124,135)'>C</span> <span style='color:rgb(126,126,132)'>C</span> <span style='color:rgb(113,113,157)'>T</span> <span style='color:rgb(124,124,136)'>A</span> <span style='color:rgb(128,128,127)'>A</span> <span style='color:rgb(102,102,180)'>C</span> <span style='color:rgb(178,103,103)'>G</span> <span style='color:rgb(157,113,113)'>G</span> <span style='color:rgb(108,108,168)'>A</span> <span style='color:rgb(179,102,102)'>G</span> <span style='color:rgb(221,81,81);font-weight:bold'>G</span> <span style='color:rgb(234,75,75);font-weight:bold'>G</span> <span style='color:rgb(173,105,105)'>G</span> <span style='color:rgb(92,92,200);font-weight:bold'>T</span> <span style='color:rgb(126,126,132)'>C</span> <span style='color:rgb(120,120,143)'>C</span> <span style='color:rgb(124,124,136)'>A</span> <span style='color:rgb(118,118,148)'>T</span> <span style='color:rgb(121,121,142)'>A</span> <span style='color:rgb(126,126,132)'>G</span> <span style='color:rgb(147,118,118)'>G</span> <span style='color:rgb(120,120,143)'>A</span> <span style='color:rgb(128,128,127)'>G</span> <span style='color:rgb(111,111,161)'>T</span> <span style='color:rgb(129,127,127)'>C</span> <span style='color:rgb(113,113,158)'>T</span> <span style='color:rgb(117,117,150)'>T</span> <span style='color:rgb(131,126,126)'>G</span> <span style='color:rgb(126,126,131)'>C</span> <span style='color:rgb(154,115,115)'>G</span> <span style='color:rgb(154,115,115)'>G</span> <span style='color:rgb(139,122,122)'>G</span> <span style='color:rgb(121,121,141)'>A</span> <span style='color:rgb(122,122,139)'>C</span> <span style='color:rgb(115,115,153)'>T</span> <span style='color:rgb(124,124,136)'>C</span> <span style='color:rgb(126,126,132)'>C</span> <span style='color:rgb(127,127,130)'>C</span> <span style='color:rgb(123,123,137)'>T</span> <span style='color:rgb(151,116,116)'>G</span> <span style='color:rgb(138,123,123)'>G</span> <span style='color:rgb(123,123,137)'>C</span> <span style='color:rgb(128,128,127)'>A</span> <span style='color:rgb(126,126,132)'>C</span> <span style='color:rgb(122,122,139)'>T</span> <span style='color:rgb(127,128,128)'>G</span> <span style='color:rgb(126,126,132)'>G</span> <span style='color:rgb(126,126,132)'>A</span> <span style='color:rgb(124,124,135)'>G</span> <span style='color:rgb(120,120,144)'>T</span> <span style='color:rgb(126,126,132)'>A</span> <span style='color:rgb(127,127,129)'>G</span> <span style='color:rgb(119,119,145)'>T</span> <span style='color:rgb(126,126,131)'>A</span> <span style='color:rgb(117,117,149)'>T</span> <span style='color:rgb(127,127,130)'>C</span> <span style='color:rgb(126,126,131)'>G</span> <span style='color:rgb(122,122,139)'>A</span> <span style='color:rgb(126,126,131)'>C</span> <span style='color:rgb(125,125,134)'>A</span> <span style='color:rgb(118,118,147)'>T</span> <span style='color:rgb(124,124,136)'>A</span> <span style='color:rgb(128,128,128)'>A</span> <span style='color:rgb(127,127,130)'>G</span> <span style='color:rgb(129,127,127)'>G</span> <span style='color:rgb(127,127,130)'>G</span> <span style='color:rgb(118,118,147)'>T</span> <span style='color:rgb(125,125,133)'>C</span> <span style='color:rgb(128,128,128)'>A</span> <span style='color:rgb(125,125,134)'>C</span> <span style='color:rgb(127,128,128)'>G</span> <span style='color:rgb(127,127,130)'>G</span> <span style='color:rgb(124,124,135)'>A</span> <span style='color:rgb(126,126,131)'>C</span> <span style='color:rgb(127,127,129)'>G</span> <span style='color:rgb(124,124,136)'>T</span> <span style='color:rgb(123,123,137)'>T</span> <span style='color:rgb(127,127,130)'>C</span> <span style='color:rgb(128,128,127)'>C</span> <span style='color:rgb(128,128,128)'>A</span> <span style='color:rgb(125,125,134)'>T</span> <span style='color:rgb(127,128,128)'>T</span> <span style='color:rgb(126,126,132)'>T</span> <span style='color:rgb(127,127,129)'>A</span> <span style='color:rgb(128,128,128)'>G</span> <span style='color:rgb(126,126,131)'>T</span> <span style='color:rgb(128,128,128)'>G</span> <span style='color:rgb(128,128,128)'>A</span> <span style='color:rgb(127,128,128)'>G</span> <span style='color:rgb(128,128,127)'>C</span> <span style='color:rgb(128,128,128)'>C</span> <span style='color:rgb(128,128,127)'>A</span> <span style='color:rgb(128,128,127)'>T</span> <span style='color:rgb(127,128,128)'>T</span> <span style='color:rgb(128,128,128)'>T</span> <span style='color:rgb(128,128,127)'>A</span> <span style='color:rgb(128,128,127)'>T</span> <span style='color:rgb(128,128,127)'>A</span> <span style='color:rgb(127,128,128)'>A</span> <span style='color:rgb(128,128,127)'>A</span> <span style='color:rgb(128,128,127)'>C</span> <span style='color:rgb(128,128,127)'>C</span> <span style='color:rgb(128,128,127)'>A</span> <span style='color:rgb(128,128,127)'>C</span> <span style='color:rgb(128,128,127)'>T</span> <span style='color:rgb(128,128,127)'>A</span> <span style='color:rgb(128,128,127)'>T</span> <span style='color:rgb(128,128,127)'>C</span> <span style='color:rgb(128,128,127)'>A</span> <span style='color:rgb(128,128,127)'>A</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWNtpE8ChoNz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}